# matching-no-matching

**Match Outcome Prediction**
This project demonstrates a complete deep learning workflow, from synthetic data collection to model training, optimization, and deployment through an interactive Streamlit app for real-time match outcome prediction.

ğŸ“Œ Highlights
ğŸ“Š Synthetic Data Collection via Google Forms

ğŸ§  Unsupervised Labeling using KMeans

ğŸ” ANN with L2 Regularization, Dropout & BatchNorm

ğŸ§ª Inference via Command Line with Argparse

ğŸŒ Interactive Streamlit App

ğŸ” Hyperparameter Tuning using Optuna (Grid, Random, Bayesian)

ğŸ¯ Overview
This project involves the development of an Artificial Neural Network (ANN) to predict match outcomes based on synthetic user-generated input features. The model can be utilized through:

âš™ Command-Line Interface (CLI) â€“ Enables predictions via terminal using an inference script

ğŸŒ Interactive Web App â€“ Provides a user-friendly Streamlit interface, deployable locally or on Hugging Face Spaces

ğŸ“Š Data Collection
Source: Synthetic (collected via Google Form)
Entries: 140+ responses
Cleaning: Dropped columns like Timestamp, Email Address
ğŸ· Data Labeling
Technique: KMeans Clustering (n_clusters=2)
Why: Automatically generates labels by uncovering hidden patterns in the dataâ€”no manual annotation or predefined rules required
ğŸ”§ Data Preprocessing
Label Encoding: Converted categorical labels to integers using LabelEncoder
Why: Efficient for small datasets with clear label classes
ğŸ§  Model Architecture
Layer Type	Details
Input Layer	Shape: (10,)
Dense Layer #1	8 units, PReLU, Glorot Initialization
Dense Layer #2	3 units, PReLU, L2 Regularization
BatchNorm + Dropout	20% Dropout
Output Layer	1 unit, Sigmoid
Optimizer: Adam
Loss: Binary Crossentropy
Metrics: Accuracy, Precision, Recall

ğŸŒ Streamlit App
ğŸš€ Deployable on Hugging Face or run locally!:

ğŸ“¥ Accepts user input via dropdowns
ğŸ”® Predicts match outcome with a confidence score
ğŸ§  Supports real-time model training
ğŸ’» Hugging Face Demo:

streamlit run app.py
ğŸ§ª Inference Script (CLI)
Use the run.py script to make predictions from the terminal.

Built an inference script using argparse to allow CLI usage:

--weights_path: Path to trained model
--data_path: Path to prediction data (default: data.csv)
--num_preds: Number of samples to predict
Used Python's time module to measure prediction time.

Example:

python run.py --weights_path weights.h5 --data_path data.csv --num_preds 5

ğŸ§  Output:

total time taken for 5 prediction is 0.0892 seconds
ğŸ’˜ It's a Match!
ğŸ’” No Match.
ğŸ“ˆ Hyperparameter Optimization
Used Optuna for tuning with:

âœ… Grid Search

ğŸ² Random Search

ğŸ” Bayesian Optimization

ğŸ”¥ Best Result (Bayesian Optimization)
Accuracy: 93.33%

Validation Precision: 1.0000

Validation Recall: 0.8000

âš™ Technologies Used
Python ğŸ

TensorFlow/Keras ğŸ§ 

Scikit-learn (LabelEncoder, KMeans)

Streamlit (UI)

Optuna (Tuning)

Argparse (CLI interface)

ğŸš€ Getting Started
1ï¸âƒ£ Clone the Repository:
git clone 
cd match-prediction-ann
2ï¸âƒ£ Install Dependencies:
pip install -r requirements.txt
3ï¸âƒ£ Run Inference Script:
python inference.py --weights_path weights.h5 --num_preds 5
4ï¸âƒ£ Launch Streamlit App:
streamlit run app.py
ğŸ“‚ Project Structure
